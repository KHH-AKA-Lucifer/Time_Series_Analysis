{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Trading Prediction with LSTM\n",
    "\n",
    "What is LSTM?\n",
    "\n",
    "LSTM = Long Short-Term Memory\n",
    "LSTM networks are specially designed to remember and process sequences of data over a long period. They are better than traditional RNNs. \n",
    "*\tCan preserve information for long durations. \n",
    "*\tUnique structure comprising three gates: the input, forget, and output gates.\n",
    "*\tThese gates collaboratively manage the flow of information, deciding what to retain and what to discard, by mitigating the issue of vanishing gradients, a common problem in standard RNNs.\n",
    "\n",
    "LSTM networks adeptly capture temporal dependencies, making them ideal for financial time series analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libaraies\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model packages\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold data are successfully downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download the required data from yfinance\n",
    "gold_one_day = yf.download('GC=F', start=\"2024-06-04\", end=\"2024-06-05\", interval=\"1m\")\n",
    "gold_one_year = yf.download('GC=F', period='1y')\n",
    "gold_ten_year = yf.download('GC=F', period='10y')\n",
    "print(\"Gold data are successfully downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-04 00:00:00-04:00</th>\n",
       "      <td>2366.000000</td>\n",
       "      <td>2366.399902</td>\n",
       "      <td>2365.399902</td>\n",
       "      <td>2365.899902</td>\n",
       "      <td>2365.899902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04 00:01:00-04:00</th>\n",
       "      <td>2365.899902</td>\n",
       "      <td>2366.300049</td>\n",
       "      <td>2365.600098</td>\n",
       "      <td>2366.100098</td>\n",
       "      <td>2366.100098</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04 00:02:00-04:00</th>\n",
       "      <td>2366.000000</td>\n",
       "      <td>2366.699951</td>\n",
       "      <td>2365.800049</td>\n",
       "      <td>2366.699951</td>\n",
       "      <td>2366.699951</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04 00:03:00-04:00</th>\n",
       "      <td>2366.800049</td>\n",
       "      <td>2366.899902</td>\n",
       "      <td>2366.300049</td>\n",
       "      <td>2366.899902</td>\n",
       "      <td>2366.899902</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04 00:04:00-04:00</th>\n",
       "      <td>2366.800049</td>\n",
       "      <td>2367.100098</td>\n",
       "      <td>2366.800049</td>\n",
       "      <td>2367.000000</td>\n",
       "      <td>2367.000000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Datetime                                                                        \n",
       "2024-06-04 00:00:00-04:00  2366.000000  2366.399902  2365.399902  2365.899902   \n",
       "2024-06-04 00:01:00-04:00  2365.899902  2366.300049  2365.600098  2366.100098   \n",
       "2024-06-04 00:02:00-04:00  2366.000000  2366.699951  2365.800049  2366.699951   \n",
       "2024-06-04 00:03:00-04:00  2366.800049  2366.899902  2366.300049  2366.899902   \n",
       "2024-06-04 00:04:00-04:00  2366.800049  2367.100098  2366.800049  2367.000000   \n",
       "\n",
       "                             Adj Close  Volume  \n",
       "Datetime                                        \n",
       "2024-06-04 00:00:00-04:00  2365.899902       0  \n",
       "2024-06-04 00:01:00-04:00  2366.100098     199  \n",
       "2024-06-04 00:02:00-04:00  2366.699951     132  \n",
       "2024-06-04 00:03:00-04:00  2366.899902      56  \n",
       "2024-06-04 00:04:00-04:00  2367.000000      86  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout gold data for one day\n",
    "gold_one_day.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-12</th>\n",
       "      <td>1959.699951</td>\n",
       "      <td>1963.500000</td>\n",
       "      <td>1951.400024</td>\n",
       "      <td>1955.300049</td>\n",
       "      <td>1955.300049</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-13</th>\n",
       "      <td>1960.599976</td>\n",
       "      <td>1967.500000</td>\n",
       "      <td>1940.300049</td>\n",
       "      <td>1944.599976</td>\n",
       "      <td>1944.599976</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-14</th>\n",
       "      <td>1946.199951</td>\n",
       "      <td>1958.199951</td>\n",
       "      <td>1940.300049</td>\n",
       "      <td>1955.300049</td>\n",
       "      <td>1955.300049</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-15</th>\n",
       "      <td>1941.699951</td>\n",
       "      <td>1958.800049</td>\n",
       "      <td>1926.000000</td>\n",
       "      <td>1957.800049</td>\n",
       "      <td>1957.800049</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-16</th>\n",
       "      <td>1961.400024</td>\n",
       "      <td>1962.900024</td>\n",
       "      <td>1953.500000</td>\n",
       "      <td>1958.400024</td>\n",
       "      <td>1958.400024</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2023-06-12  1959.699951  1963.500000  1951.400024  1955.300049  1955.300049   \n",
       "2023-06-13  1960.599976  1967.500000  1940.300049  1944.599976  1944.599976   \n",
       "2023-06-14  1946.199951  1958.199951  1940.300049  1955.300049  1955.300049   \n",
       "2023-06-15  1941.699951  1958.800049  1926.000000  1957.800049  1957.800049   \n",
       "2023-06-16  1961.400024  1962.900024  1953.500000  1958.400024  1958.400024   \n",
       "\n",
       "            Volume  \n",
       "Date                \n",
       "2023-06-12     212  \n",
       "2023-06-13     343  \n",
       "2023-06-14     202  \n",
       "2023-06-15     329  \n",
       "2023-06-16     119  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout gold data for one year\n",
    "gold_one_year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-12</th>\n",
       "      <td>1260.000000</td>\n",
       "      <td>1274.500000</td>\n",
       "      <td>1260.000000</td>\n",
       "      <td>1273.599976</td>\n",
       "      <td>1273.599976</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-13</th>\n",
       "      <td>1272.500000</td>\n",
       "      <td>1274.699951</td>\n",
       "      <td>1271.300049</td>\n",
       "      <td>1273.699951</td>\n",
       "      <td>1273.699951</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-16</th>\n",
       "      <td>1279.800049</td>\n",
       "      <td>1282.099976</td>\n",
       "      <td>1270.800049</td>\n",
       "      <td>1274.900024</td>\n",
       "      <td>1274.900024</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-17</th>\n",
       "      <td>1272.800049</td>\n",
       "      <td>1272.800049</td>\n",
       "      <td>1260.900024</td>\n",
       "      <td>1271.699951</td>\n",
       "      <td>1271.699951</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-18</th>\n",
       "      <td>1269.900024</td>\n",
       "      <td>1272.699951</td>\n",
       "      <td>1267.400024</td>\n",
       "      <td>1272.400024</td>\n",
       "      <td>1272.400024</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2014-06-12  1260.000000  1274.500000  1260.000000  1273.599976  1273.599976   \n",
       "2014-06-13  1272.500000  1274.699951  1271.300049  1273.699951  1273.699951   \n",
       "2014-06-16  1279.800049  1282.099976  1270.800049  1274.900024  1274.900024   \n",
       "2014-06-17  1272.800049  1272.800049  1260.900024  1271.699951  1271.699951   \n",
       "2014-06-18  1269.900024  1272.699951  1267.400024  1272.400024  1272.400024   \n",
       "\n",
       "            Volume  \n",
       "Date                \n",
       "2014-06-12     129  \n",
       "2014-06-13     145  \n",
       "2014-06-16     334  \n",
       "2014-06-17     819  \n",
       "2014-06-18     143  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout gold data for one year\n",
    "gold_ten_year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold data one day\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "------------------\n",
      "Gold data one year\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "------------------\n",
      "Gold data ten years\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check out if there is missing value \n",
    "print(\"Gold data one day\")\n",
    "print(gold_one_day.isna().sum())\n",
    "print(\"------------------\")\n",
    "print(\"Gold data one year\")\n",
    "print(gold_one_year.isna().sum())\n",
    "print(\"------------------\")\n",
    "print(\"Gold data ten years\")\n",
    "print(gold_ten_year.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "gold_one_day_scaled = scaler.fit_transform(gold_one_day['Close'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84444173],\n",
       "       [0.85000271],\n",
       "       [0.86666531],\n",
       "       ...,\n",
       "       [0.59166802],\n",
       "       [0.59166802],\n",
       "       [0.59444173]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_one_day_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1364, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_one_day_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty lists\n",
    "X = []\n",
    "y = []\n",
    "# loop to create a 60-1min-sequence\n",
    "for i in range(60, len(gold_one_day_scaled)):\n",
    "    X.append(gold_one_day_scaled[i-60:i, 0])\n",
    "    y.append(gold_one_day_scaled[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "train_size = int(len(X) * 0.8)\n",
    "test_size = len(X) - train_size\n",
    "\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to train in LSTM model ([samples, time steps, features]) \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, AdditiveAttention, Permute, Reshape, Multiply\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding LSTM layers with return_sequences=True\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding self-attention mechanism\n",
    "# The attention mechanism\n",
    "attention = AdditiveAttention(name='attention_weight')\n",
    "# Permute and reshape for compatibility\n",
    "model.add(Permute((2, 1))) \n",
    "model.add(Reshape((-1, X_train.shape[1])))\n",
    "# compute attention result \n",
    "attention_result = attention([model.output, model.output])\n",
    "# perform element-wise multiplication of the model's output and the attention result\n",
    "multiply_layer = Multiply()([model.output, attention_result])\n",
    "# Adding a Flatten layer before the final Dense layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# Final Dense layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Adding Dropout and Batch Normalization\n",
    "\"\"\"Dropout helps in preventing overfitting by randomly setting a fraction of the input \n",
    "units to 0 at each update during training, and Batch Normalization stabilizes the learning \n",
    "process.\"\"\"\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 60, 50)            20200     \n",
      "                                                                 \n",
      " permute (Permute)           (None, 50, 60)            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 50, 60)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3001      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1)                 0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1)                 4         \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33605 (131.27 KB)\n",
      "Trainable params: 33603 (131.26 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# review the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 4s 43ms/step - loss: 0.4403 - val_loss: 0.0821\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.1908 - val_loss: 0.0632\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.1669 - val_loss: 0.0528\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.1450 - val_loss: 0.0364\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.1244 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.1101 - val_loss: 0.0208\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0898 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0762 - val_loss: 0.0093\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0654 - val_loss: 0.0078\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0580 - val_loss: 0.0033\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0505 - val_loss: 0.0023\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0420 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0361 - val_loss: 1.5016e-04\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0315 - val_loss: 3.5681e-04\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0277 - val_loss: 5.5408e-04\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0250 - val_loss: 1.1811e-04\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 2s 47ms/step - loss: 0.0229 - val_loss: 2.5743e-04\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0240 - val_loss: 8.4476e-04\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0187 - val_loss: 2.4785e-04\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0190 - val_loss: 2.6247e-04\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0152 - val_loss: 4.1773e-04\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0162 - val_loss: 6.9782e-04\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0149 - val_loss: 8.9297e-04\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0139 - val_loss: 0.0060\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0188 - val_loss: 0.0026\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0141 - val_loss: 0.0024\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0158 - val_loss: 0.0031\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0142 - val_loss: 0.0054\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0139 - val_loss: 1.1035e-04\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0134 - val_loss: 0.0040\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0132 - val_loss: 0.0023\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0161 - val_loss: 3.4401e-04\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0142 - val_loss: 0.0024\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0137 - val_loss: 7.3787e-05\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0137 - val_loss: 4.9865e-04\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0171 - val_loss: 2.7702e-04\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0170 - val_loss: 6.8255e-04\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0160 - val_loss: 0.0042\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0183 - val_loss: 7.6525e-04\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0181 - val_loss: 0.0040\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.0162 - val_loss: 7.2542e-05\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0144 - val_loss: 0.0044\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0135 - val_loss: 0.0070\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0167 - val_loss: 3.6875e-04\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0150 - val_loss: 0.0054\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0152 - val_loss: 1.5010e-04\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0135 - val_loss: 6.1574e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0143 - val_loss: 0.0066\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0145 - val_loss: 3.6761e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.0124 - val_loss: 8.6412e-05\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0147 - val_loss: 0.0027\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0148 - val_loss: 0.0027\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 2s 46ms/step - loss: 0.0154 - val_loss: 0.0018\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.0148 - val_loss: 0.0040\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0150 - val_loss: 0.0037\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0169 - val_loss: 8.1905e-05\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.0157 - val_loss: 0.0076\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 1s 42ms/step - loss: 0.0163 - val_loss: 3.6976e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0159 - val_loss: 6.7651e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0135 - val_loss: 0.0042\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0150 - val_loss: 9.4681e-04\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0174 - val_loss: 0.0010\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0202 - val_loss: 7.7013e-04\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0180 - val_loss: 2.4611e-04\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 2s 48ms/step - loss: 0.0151 - val_loss: 7.5357e-05\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0150 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0153 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0155 - val_loss: 0.0064\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0169 - val_loss: 0.0056\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 1s 42ms/step - loss: 0.0161 - val_loss: 0.0037\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 2s 46ms/step - loss: 0.0155 - val_loss: 7.3779e-05\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0167 - val_loss: 2.7913e-04\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0143 - val_loss: 0.0073\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0137 - val_loss: 7.4037e-04\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0130 - val_loss: 8.0912e-04\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0154 - val_loss: 1.5620e-04\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0157 - val_loss: 7.4731e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.0145 - val_loss: 5.7750e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.0157 - val_loss: 6.0101e-05\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 2s 44ms/step - loss: 0.0136 - val_loss: 0.0015\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 2s 49ms/step - loss: 0.0133 - val_loss: 8.7191e-04\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.0142 - val_loss: 0.0031\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 0.0138 - val_loss: 1.0172e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 2s 52ms/step - loss: 0.0120 - val_loss: 4.1282e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 2s 59ms/step - loss: 0.0156 - val_loss: 0.0018\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 0.0150 - val_loss: 9.6082e-05\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 2s 49ms/step - loss: 0.0129 - val_loss: 5.5829e-05\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 2s 49ms/step - loss: 0.0139 - val_loss: 2.6839e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 2s 59ms/step - loss: 0.0140 - val_loss: 0.0036\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 2s 59ms/step - loss: 0.0153 - val_loss: 0.0023\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 2s 46ms/step - loss: 0.0150 - val_loss: 0.0059\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 0.0119 - val_loss: 9.0980e-05\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 2s 54ms/step - loss: 0.0120 - val_loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are already defined and preprocessed\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0026\n",
      "Test Loss:  0.0025574816390872\n"
     ]
    }
   ],
   "source": [
    "# Convert X_test and y_test to Numpy arrays if they are not already\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Ensure X_test is reshaped similarly to how X_train was reshaped\n",
    "# This depends on how you preprocessed the training data\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Now evaluate the model on the test data\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 15ms/step\n",
      "Mean Absolute Error:  0.04536230282968522\n",
      "Root Mean Square Error:  0.05057154919235595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating MAE and RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"Root Mean Square Error: \", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetching the latest 60 days of AAPL stock data\n",
    "test_data = yf.download('GC=F', interval='1m', period='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:00:00-04:00</th>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.600098</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.300049</td>\n",
       "      <td>2330.300049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:01:00-04:00</th>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.600098</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.600098</td>\n",
       "      <td>2330.600098</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:02:00-04:00</th>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.399902</td>\n",
       "      <td>2330.399902</td>\n",
       "      <td>2330.399902</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:03:00-04:00</th>\n",
       "      <td>2330.300049</td>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.300049</td>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:04:00-04:00</th>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.899902</td>\n",
       "      <td>2330.500000</td>\n",
       "      <td>2330.800049</td>\n",
       "      <td>2330.800049</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Datetime                                                                        \n",
       "2024-06-12 00:00:00-04:00  2330.500000  2330.600098  2330.199951  2330.300049   \n",
       "2024-06-12 00:01:00-04:00  2330.199951  2330.600098  2330.199951  2330.600098   \n",
       "2024-06-12 00:02:00-04:00  2330.500000  2330.500000  2330.399902  2330.399902   \n",
       "2024-06-12 00:03:00-04:00  2330.300049  2330.500000  2330.300049  2330.500000   \n",
       "2024-06-12 00:04:00-04:00  2330.500000  2330.899902  2330.500000  2330.800049   \n",
       "\n",
       "                             Adj Close  Volume  \n",
       "Datetime                                        \n",
       "2024-06-12 00:00:00-04:00  2330.300049       0  \n",
       "2024-06-12 00:01:00-04:00  2330.600098      18  \n",
       "2024-06-12 00:02:00-04:00  2330.399902       4  \n",
       "2024-06-12 00:03:00-04:00  2330.500000       7  \n",
       "2024-06-12 00:04:00-04:00  2330.800049      13  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:44:00-04:00</th>\n",
       "      <td>2329.699951</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2329.699951</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:45:00-04:00</th>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:46:00-04:00</th>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.100098</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:47:00-04:00</th>\n",
       "      <td>2330.100098</td>\n",
       "      <td>2330.399902</td>\n",
       "      <td>2330.100098</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-12 00:48:00-04:00</th>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.300049</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>2330.199951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Datetime                                                                        \n",
       "2024-06-12 00:44:00-04:00  2329.699951  2330.000000  2329.699951  2330.000000   \n",
       "2024-06-12 00:45:00-04:00  2330.000000  2330.199951  2330.000000  2330.199951   \n",
       "2024-06-12 00:46:00-04:00  2330.199951  2330.199951  2330.100098  2330.199951   \n",
       "2024-06-12 00:47:00-04:00  2330.100098  2330.399902  2330.100098  2330.199951   \n",
       "2024-06-12 00:48:00-04:00  2330.199951  2330.300049  2330.199951  2330.199951   \n",
       "\n",
       "                             Adj Close  Volume  \n",
       "Datetime                                        \n",
       "2024-06-12 00:44:00-04:00  2330.000000      15  \n",
       "2024-06-12 00:45:00-04:00  2330.199951      19  \n",
       "2024-06-12 00:46:00-04:00  2330.199951      11  \n",
       "2024-06-12 00:47:00-04:00  2330.199951      20  \n",
       "2024-06-12 00:48:00-04:00  2330.199951       0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 49 into shape (60,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(closing_prices\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Since we need the last 60 days to predict the next day, we reshape the data accordingly\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_latest \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mscaled_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Reshaping the data for the model (adding batch dimension)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X_latest \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X_latest, (X_latest\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_latest\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 49 into shape (60,)"
     ]
    }
   ],
   "source": [
    "# Selecting the 'Close' price and converting to numpy array\n",
    "closing_prices = test_data['Close'].values\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(closing_prices.reshape(-1,1))\n",
    "\n",
    "# Since we need the last 60 days to predict the next day, we reshape the data accordingly\n",
    "X_latest = np.array([scaled_data[-60:].reshape(60)])\n",
    "\n",
    "# Reshaping the data for the model (adding batch dimension)\n",
    "X_latest = np.reshape(X_latest, (X_latest.shape[0], X_latest.shape[1], 1))\n",
    "\n",
    "# Making predictions for the next 4 candles\n",
    "predicted_stock_price = model.predict(X_latest)\n",
    "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n",
    "\n",
    "print(\"Predicted Gold Prices for the next day: \", predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the next 4 days iteratively\n",
    "predicted_prices = []\n",
    "current_batch = scaled_data[-60:].reshape(1, 60, 1)  # Most recent 60 days\n",
    "\n",
    "for i in range(4):  # Predicting 4 days\n",
    "    # Get the prediction (next day)\n",
    "    next_prediction = model.predict(current_batch)\n",
    "    \n",
    "    # Reshape the prediction to fit the batch dimension\n",
    "    next_prediction_reshaped = next_prediction.reshape(1, 1, 1)\n",
    "    \n",
    "    # Append the prediction to the batch used for predicting\n",
    "    current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)\n",
    "    \n",
    "    # Inverse transform the prediction to the original price scale\n",
    "    predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])\n",
    "\n",
    "print(\"Predicted Gold Prices for the next 4 days: \", predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mplfinance -qqq\n",
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mpl_dates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is your DataFrame with the fetched AAPL stock data\n",
    "# Make sure it contains Open, High, Low, Close, and Volume columns\n",
    "\n",
    "# Creating a list of dates for the predictions\n",
    "last_date = test_data.index[-1]\n",
    "next_day = last_date + pd.Timedelta(days=1)\n",
    "prediction_dates = pd.date_range(start=next_day, periods=4)\n",
    "\n",
    "# Assuming 'predicted_prices' is your list of predicted prices for the next 4 days\n",
    "predictions_df = pd.DataFrame(index=prediction_dates, data=predicted_prices, columns=['Close'])\n",
    "\n",
    "# Plotting the actual data with mplfinance\n",
    "mpf.plot(test_data, type='candle', style='charles', volume=True)\n",
    "\n",
    "# Overlaying the predicted data\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(predictions_df.index, predictions_df['Close'], linestyle='dashed', marker='o', color='red')\n",
    "\n",
    "plt.title(\"AAPL Stock Price with Predicted Next 4 Days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mpl_dates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fetch the latest 60 days of AAPL stock data\n",
    "data = yf.download('GC=F', period='3mo', interval='1d') # Fetch 64 days to display last 60 days in the chart\n",
    "\n",
    "# Select 'Close' price and scale it\n",
    "closing_prices = data['Close'].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(closing_prices)\n",
    "\n",
    "# Predict the next 4 days iteratively\n",
    "predicted_prices = []\n",
    "current_batch = scaled_data[-60:].reshape(1, 60, 1)  # Most recent 60 days\n",
    "\n",
    "for i in range(4):  # Predicting 4 days\n",
    "    next_prediction = model.predict(current_batch)\n",
    "    next_prediction_reshaped = next_prediction.reshape(1, 1, 1)\n",
    "    current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)\n",
    "    predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])\n",
    "\n",
    "# Creating a list of dates for the predictions\n",
    "last_date = data.index[-1]\n",
    "next_day = last_date + pd.Timedelta(days=1)\n",
    "prediction_dates = pd.date_range(start=next_day, periods=4)\n",
    "\n",
    "# Adding predictions to the DataFrame\n",
    "predicted_data = pd.DataFrame(index=prediction_dates, data=predicted_prices, columns=['Close'])\n",
    "\n",
    "# Combining both actual and predicted data\n",
    "combined_data = pd.concat([data['Close'], predicted_data['Close']])\n",
    "combined_data = combined_data[-64:] # Last 60 days of actual data + 4 days of predictions\n",
    "\n",
    "# Plotting the actual data\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(data.index[-60:], data['Close'][-60:], linestyle='-', marker='o', color='blue', label='Actual Data')\n",
    "\n",
    "# Plotting the predicted data\n",
    "plt.plot(prediction_dates, predicted_prices, linestyle='-', marker='o', color='red', label='Predicted Data')\n",
    "\n",
    "plt.title(\"Gold Price: Last 60 Days and Next 4 Days Predicted\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
