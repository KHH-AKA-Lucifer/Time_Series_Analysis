{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries \n",
    "import os\n",
    "import warnings \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrangle(path, dropped_columns=None):\n",
    "    \"\"\"A method that cleans the original dataset,\n",
    "       restructures the dataset, and fills the missing values.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Data path to the CSV file.\n",
    "    dropped_columns : list, optional\n",
    "        Columns to be dropped (default is None).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned and structured dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the dataset from the given path\n",
    "    df = pd.read_csv(path, header=None, names=[\"Date\", \"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "    \n",
    "    # Combine Date and Time columns into a single Date column\n",
    "    df['Date'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "    \n",
    "    # Drop the now redundant Time column\n",
    "    df.drop(columns=[\"Time\"], inplace=True)\n",
    "    \n",
    "    # If there are any unnecessary columns specified, drop them\n",
    "    if dropped_columns:\n",
    "        df = df.drop(columns=dropped_columns)\n",
    "    \n",
    "    # Set the Date column as the index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Return the cleaned dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets \n",
    "df_1min = data_wrangle('data/XAUUSD_1min.csv')\n",
    "# df_4hr = data_wrangle('data/XAUUSD_4hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min.to_csv('data/gold_minutely_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate CCI\n",
    "def calculate_cci(data, period):\n",
    "\n",
    "    # calculate the typical price\n",
    "    data['Typical Price'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "\n",
    "    # calculate the simple moving average (SMA) of the Typical Price\n",
    "    sma = data['Typical Price'].rolling(window=period).mean()\n",
    "\n",
    "    # calculate the mean deviation\n",
    "    mean_deviation = data['Typical Price'].rolling(window=period).apply(\n",
    "        lambda x: pd.Series(x).mad())\n",
    "\n",
    "    # calculate the CCI\n",
    "    cci = (data['Typical Price'] - sma) / (0.015 * mean_deviation)\n",
    "    \n",
    "    return cci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate CCI for 3-period and 9-period\n",
    "data['CCI_3'] = calculate_cci(data, 3)\n",
    "data['CCI_9'] = calculate_cci(data, 9)\n",
    "\n",
    "# Display the data with CCI columns\n",
    "print(data[['Date', 'High', 'Low', 'Close', 'CCI_3', 'CCI_9']].tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
